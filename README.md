# Сервис для автоматического выполнения задачи по написанию приложений или выполнения иных задач с помощью ai агента.

## Описание
Данный сервис предназначен для автоматического выполнения работы с помошью ai агента и сохранения данных в GitHub.
Он позволяет создавать, изменять файлы, управлять ветками, коммитами, пулл-реквестами и код-ревью.
Ai агент может выполнять и другие сложные задачи не касающиеся кода, например подготовку презентаций, сбор и структурирование данных по определенной теме.

## Технологии
- Python 3.12+
- Django: Веб-фреймворк
- Celery Beat & Worker: Для асинхронных и периодических задач
- SQLite: Легковесная база данных для хранения конфигурации и состояния
- Google Gemini Flash API: Для генерации кода и текстового контента
- Docker & Docker Compose: Для контейнеризации и оркестрации сервисов
- UV: Менеджер пакетов

## Установка и запуск

### 1. Клонирование репозитория
```bash
git clone <URL_ВАШЕГО_РЕПОЗИТОРИЯ>
cd ai_agent_creator
```

### 2. Установка зависимостей с помощью UV
Убедитесь, что у вас установлен `uv`. Если нет, вы можете установить его, следуя инструкциям на [официальном сайте UV](https://astral.sh/uv/install/).

После установки `uv`, перейдите в корневую директорию проекта и установите зависимости:
```bash
uv sync
```

### 3. Настройка переменных окружения
Создайте файл `.env` в корне проекта на основе `example.env` (будет создан позже) и заполните его необходимыми данными:

```dotenv
DJANGO_SETTINGS_MODULE=ai_agent_creator.settings
DJANGO_SECRET_KEY=ВАШ_СЕКРЕТНЫЙ_КЛЮЧ
DEBUG=True
ALLOWED_HOSTS='["localhost"]'
CSRF_TRUSTED_ORIGINS='["localhost"]'
# Google Gemini API
GEMINI_API_KEY=ВАШ_GEMINI_API_КЛЮЧ

# Celery Redis Broker
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# Отладочные настройки для Docker
PYTHONUNBUFFERED=1
```

### 4. Запуск с помощью Docker Compose
```bash
docker-compose up --build
```

Это поднимет следующие сервисы:
- `web`: Django веб-приложение
- `celery_worker`: Воркер Celery для выполнения задач
- `celery_beat`: Планировщик Celery для периодических задач
- `redis`: Брокер сообщений для Celery

### 5. Применение миграций (после первого запуска)
После того как контейнеры запустятся, выполните миграции Django:
```bash
docker-compose exec web python manage.py migrate
```

### 6. Создание суперпользователя (опционально)
Для доступа к Django Admin:
```bash
docker-compose exec web python manage.py createsuperuser
```

## Использование

После запуска всех сервисов Docker Compose, вы сможете настроить и управлять проектом через административную панель Django и запускать задачи генерации активности.

### 1. Доступ к Django Admin

Откройте в браузере адрес `http://localhost:8000/admin/`. Используйте учетные данные суперпользователя, созданные ранее, для входа.

### 2. Настройка основных сущностей

В административной панели вы увидите следующие модели:

-   **Репозитории (Repositories)**:
    *   Создайте новый репозиторий. Укажите `Название` (например, `my-github-repo`), `URL` (полный URL вашего репозитория GitHub, например, `https://github.com/your-username/your-repo-name.git`) и `GitHub токен` (ваш личный токен доступа GitHub с разрешениями на репозитории).
    *   `Последняя дата активности` будет обновляться автоматически при генерации.

-   **Темы проектов (Project themes)**:
    *   Создайте новую тему проекта. Укажите `Название` (например, `Python Web Development`) и `Начальный промпт для AI` (подробное описание темы, которое поможет AI генерировать осмысленный код, например: "A Django REST API for managing tasks, including user authentication, CRUD operations for tasks, and simple reporting.").
    *   `Текущий контекст проекта для AI` будет обновляться автоматически AI по мере выполнения задачи.

-   **Расписание активности (Activity schedules)**:
    *   Создайте расписание для выбранного `Репозитория`. Укажите `Дни недели` (например, `Mon,Tue,Wed,Thu,Fri` для рабочих дней), `Время начала` и `Время окончания` (в UTC), в течение которых может выполняться вполнение задач.
    *   **Важно**: Celery Beat будет автоматически запускать задачу `generate_and_commit_code` на основе этих расписаний. Активность будет происходить ежедневно в заданное время и дни, что очень удобно если используются бесплатные лимиты моделей например geminy.


### 3. Мониторинг активности

-   **Логи Docker Compose**: Следите за логами контейнеров `celery_worker` и `celery_beat` для отслеживания выполнения задач и ошибок.
    ```bash
    docker-compose logs -f celery_worker
    docker-compose logs -f celery_beat
    ```
-   **GitHub Репозиторий**: Проверяйте ваш репозиторий GitHub на наличие новых веток, коммитов, пулл-реквестов и их слияний.

### Как это работает автоматически?

-   **Celery Beat**: Этот сервис отвечает за планирование периодических задач. Он будет обращаться к базе данных Django (через `django_celery_beat`) соответствующее время и дни.
-   **Celery Worker**: Этот сервис выполняет задачи, поставленные Celery Beat или инициированные через API. Он будет взаимодействовать с GitHub и AI model API для выполнения операций по генерации активности.

## Развертывание

Для развертывания проекта в production-окружении рекомендуется использовать Docker. Убедитесь, что у вас установлен Docker и Docker Compose на целевом сервере.

1. **Подготовьте `.env` файл** с продакшн-значениями, в частности `DEBUG=False` и надежным `DJANGO_SECRET_KEY`.
2. **Соберите Docker-образы** (если не использовался `--build` при `docker-compose up`):
   ```bash
   docker-compose build
   ```
3. **Запустите контейнеры в production режиме** (например, с detached mode):
   ```bash
   docker-compose up -d
   ```
4. **Примените миграции**:
   ```bash
   docker-compose exec web python manage.py migrate --noinput
   ```
5. **Соберите статические файлы**:
   ```bash
   docker-compose exec web python manage.py collectstatic --noinput
   ```

Рекомендуется использовать обратный прокси-сервер (например, Nginx) для обслуживания статических файлов и проксирования запросов к Django-приложению. 